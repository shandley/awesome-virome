{
  "cache_date": "2025-03-17T03:32:46.884213",
  "data": "#### Author: Jan Felix Finke, 2022\n\n#### See [LICENSE](https://github.com/janfelix/Deep6/blob/main/LICENSE) for licensing.\n\n### Description:\nDeep6 is a reference-independent and alignment-free tool to predict viral sequences in short metatrascriptome data, it can process input contigs as short as 250 nt. Deep6 is a Convolutional Neural Networ (CNN) with 500 convolutions and 525 dense layers. Four models for different length ranges of query sequences are provided, the repository also includes scripts to custom train alternative models. The primary prediction script selects the appropriate model for each input sequence length and automatically encodes and predicts the sequence. For each sequence group a score is calculated, group scores for the six groups add to 1.00. Based on the scores, with a score of close to one describing a perfect prediciton, the final sequence prediction is derived in the downstream analysis. \n\nTo train custom models, the batch-encoding script splits sets of CDS into 90% training data and 10% validation data, chunks of CDS of appropriate length for the model in overlapping forward and reverse order are then one-hot encoded. In a next step the training script feeds the encoded training and validation data into the CNN and saves the best model. During training models are optimized for accuracy; model performance is assessed by training and validation area under receiver operating characteristic curve (AUROC), average accuracy, and group precision, recall and derived F1-scores. Additionally, a confusion matrix of sequence predictions is produced for the final model.\n\n\n### Setup Environment and Install Packages:\nClone the \"Deep6\" repository using the code button on top or in your terminal using: `git clone https://github.com/janfelix/Deep6.git`. The Master directory includes the license file, this readme file, a conda yml file and the python scripts for sequence prediction, batch encoding and custom model training. The provided R-script processes group scores per sequence into a final prediction for easy down stream processing. The Model directory contains the pre-trained default models for marine samples. \n\nThe installation instructions are focused on Linux systems and use Python 3.6, numpy, pandas, h5py, biopython, scipy, keras, tensorflow-gpu and scikit-learn. The tensorflow-gpu package can be difficult to implement for non Linux systems, custom model training when using different versions of tensorflow-gpu might be impaired. Especially for custom model training it is advised to use gpu equipped servers, any reasonably scaled model training will exceed cpu systems.\n\n#### Using virtual environment\n```\nmodule load python/3.6\nvirtualenv --no-download ~/dsix #create the empty environment\nsource ~/dsix/bin/activate\n\npip install --no-index --upgrade pip\npip install keras==2.2.4 numpy scipy pandas sklearn biopython\npip install --no-index tensorflow_gpu\npip install 'h5py==2.10.0' --force-reinstall\npip install 'scipy==1.4.1' --force-reinstall\n```\n#### Using `conda`\n\nFor Linux systems:\n\nCreate a conda environment and install required packages. This is the recommended method, but can take a few minutes. Conda will need the following channels: default, anaconda, conda-forge. If necessary add channels e.g. `conda config --add channels conda-forge`. This also works for Windows 64-bit systems.\n\n`conda create -n dsix python=3.6 numpy pandas h5py biopython scipy keras scikit-learn tensorflow-gpu`\n\nOr using the yml setup file for the specific package versions.\n\n`conda env create -n dsix -f dsix_linux.yml` \n\nFor Mac OSX systems:\n\nThere is no conda installer for tensorflow-gpu 2.6.0 for Mac OSX, the following installs tensorflow-gpu 1.1.0 through pypi. Conda will need the following channels: default, anaconda, conda-forge, pypi. If necessary add channels e.g. `conda config --add channels conda-forge`.\n```\nconda create -n dsix python=3.6 numpy pandas h5py biopython scipy keras scikit-learn\nconda activate dsix\npip install tensorflow tensorflow_gpu\n```\nOr using the yml setup file for the specific package versions, using pypi.\n\n`conda env create -n dsix -f dsix_mac.yml`\n\n### Usage:\n\n#### Predict sequences with default model, e.g. with minimum length set to 250nt\n\n`python Deep6/Master/deep6.py -i ./inputfile.fasta -l 250 -m Deep6/Models -o outdir`\n\nOptions, -i defines the input file with contigs in fasta format; -l is the minimum contig length to analyze; -m defines the directory with the models; -o defines the directory to save the outputfile.\n```\n  -h, --help            show this help message and exit\n  -i IFILE, --infile=IFILE\n                        input file\n  -l MLENGTH, --minlength=MLENGTH\n                        min length\n  -m MDIR, --mod=MDIR   model directory\n  -o ODIR, --out=ODIR   output directory\n```\n\n#### Batch encode sequences for custom training datasets, e.g. duplodnaviria with fragment length set to 250nt\n\n`python Deep6/Master/deep6_encode.py -i Deep6/Master/test_data.fasta -l 250 -c duplodnaviria`\n\nOptions, -i defines the input file with sequences to encode in fasta format, one file per training class; -l is the fragment length to encode, -c denotes the corresponding class; encoded files for training and validation are saved in the input file directories.\n```\n  -h, --help            show this help message and exit\n  -i IFILE, --infile=IFILE\n                        input file\n  -l MLENGTH, --length=MLENGTH\n                        fragment length\n  -c CCLASS, --contigclass=CCLASS\n                        class: prokaryote, eukaryote, duplodnaviria,\n                        varidnaviria, monodnaviria, riboviria\n```\n\n#### Train custom model, e.g. fragment length set to 250nt, 525 neurons, kernel size 10 for 40 epochs\n\n`python Deep6/Master/deep6_train.py -l 250 -t ./train_encode -v ./val_encode -o outdir -n 525 -k 10 -e 40`\n\nOptions, -l defines the fragment length for the specific model, corrsponding to the fragment lengths defined during batch encoding; -t defines the directory for training data; -v defines the directory for validation data; -n defines the number of dense layers (default 525); -e defines the maximum number of epochs to run model optimization.\n```\n  -h, --help            show this help message and exit\n  -l MLENGTH, --length=MLENGTH\n                        fragment length\n  -t TDIR, --train=TDIR\n                        directory for training data\n  -v VDIR, --val=VDIR   directory for validation data\n  -o ODIR, --out=ODIR   output directory\n  -n NLAYER, --nlayer=NLAYER\n                        neurons dense layer\n  -k KSIZE, --ksize=KSIZE\n                        kernel size\n  -e EPOCHS, --epochs=EPOCHS\n                        max number of epochs\n```\n\n### Test run:\n\nTo test the installation and demonstrate the function of Deep6 analyze the provided [test_data.fasta](https://github.com/janfelix/Deep6/blob/main/Master/test_data.fasta) file. This file contains one reference sequences per prokaryote, eukaryote, duplodnaviria, varidnaviria, monodnaviria, riboviria.\n\n`python Deep6/Master/deep6.py -i Deep6/Master/test_data.fasta -l 250 -m Deep6/Models -o ./`\n\n### Interpreting Results:\n\nThe provided R-script [deep6_interpretation.R](https://github.com/janfelix/Deep6/blob/main/Master/deep6_interpetration.R) assigns group prediction for each sequence based on the group with the highest score, if that score also is 1.25x higher than the median score. It also produces an overview of the contig prediction for the analysed input file. It should be noted that this is only a suggested approach to interpret the predictions. Depending on the research question it also feasible to only differentiate between e.g. any cellular vs. any viral or to consider e.g. second highest scores.\n\n### Supplementary files:\n \nSee [refseq_taxa.txt](https://github.com/janfelix/Deep6/blob/main/Master/refseq_taxa.txt) for an overview of taxa for training datasets.\n"
}