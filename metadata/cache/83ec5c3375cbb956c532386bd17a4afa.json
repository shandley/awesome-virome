{
  "cache_date": "2025-03-17T03:38:07.478930",
  "data": "![Logo](HOPS-02.png)\n## HOPS Summary ##  \n[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3362248.svg)](https://doi.org/10.5281/zenodo.3362248) [![install with bioconda](https://img.shields.io/badge/install%20with-bioconda-brightgreen.svg?style=flat)](http://bioconda.github.io/recipes/hops/README.html)\n\n\nHOPS is a java pipeline which focuses on screening MALT data (see Table of Contents) for the presence of a user-specified list of target species. The pipeline essentially exists to make it easier to use MALT and MaltExtract in unison. To use HOPS you will need a config file, which specifies some key parameters for MALT and MaltExtract. You can have multiple config files to quickly redo a previous analysis or archive them to remember parameters you used in an analysis. HOPS will in every case create a log that tells you which command was sent to Slurm, in case you encounter problems, that log file is a very good place to start looking for the problem.\n\nFor MALT check out: https://github.com/danielhuson/malt\n\nFor the hacked version of MALT with some extra functionality: https://github.com/rhuebler/cMALT\n(Please use the oringal version unless you really require some of the added functions)\n\nFor the source code to MaltExtract: https://github.com/rhuebler/MaltExtract\n\nAs a target list for MaltExtract you can try the one from the resource folder in the HOPS github repository or create your own. Just remember to specify it in a config file so HOPS can find it.\n\nFor the source code to the postprocessing scipts: https://github.com/keyfm/amps\n\nIf you encounter any problems running HOPS please contact huebler@shh.mpg.de and provide the config file you are using as well as the log file that was generated, this will greatly speed up troublehooting.\n\n## Support ##\n\nin case you run into problems please contact ron.huebler(at)yahoo.de and cc alexander_herbig(at)eva.mpg.de\n\n\n## How do I get set up? ##\n### without Conda ###\n\nIn order to run HOPS you need Java version 8 or higher and a version of MALT 036 or higher and a version of MaltExtract 1.2 or higher. You can run run the install_hops.sh to download HOPS and its dependencies (except MALT) automatically.\n\n### Conda install ###\n<code bash>conda install hops -c bioconda </code>\n\nwill install hops, maltExtract, malt and the postprocessing. HOPS will look for its dependencies at the location of the hops.jar and will assume that the malt-run script is in the Path. if for whatever reasons you have problems getting HOPS to run you can also specifically point HOPS to its dependencies via a config file. For example an older verion of MALT:\n\n**pathToMalt=../path.malt/malt-run** where to find the malt-run shellscript which comes with all implementations of malt\n\n**You will in any case need an indexed Malt Database, as such a database can easily have a size of several 100 GB HOPS does not come with a database. You can either contact me so I can share one of our prebuilt databses with you or you can built your own database via malt-build please consult the malt manual for the specifics**\n\n**index= ../indexed/database** path to chosen Malt DB, has to be constructed with MALT version 38 or higher\nto a config file for hops. \n\n### Parameters that have to be specified ###\n\nBy default HOPS will look for its dependencies at the place where the hops.jar is located. If you use the install script that will be the case by default. to allow HOPS access to MALT and the MALT database. you can add either a symlink to the hops folder by\n\n<code bash> ln -s ..path/malt-run ../path/hops/malt-run </code>\n<code bash> ln -s ..path/malt-database ../path/hops/database </code>\n\nor you can specify paths in a configfile\n\n**pathToMalt=../path.malt/malt-run** where to find the malt-run shellscript which comes with all implementations of malt]\n\n**index= ../indexed/database** path to chosen Malt DB, has to be constructed with MALT version 38 or higher\n\n**pathToMaltExtract= ../path/to/MaltExtract1.5.jar** where to find RMAExtractor.jar try to use 1.3 or higher\n\n**pathToPostProcessing= ../path/to/postprocessing.AMPS.r** where to find the postprocessig script\n\n\nif you have conflicting versions of java installed you can add to the config file\n\npathToMalt=\"../path/version/java\"\n\nto run MaltExtract with a different version of Java than Malt\n\n**pathToList=../path/to/list.txt**  specify path to postprocessing node list\n\nBy default HOPS run each step of the pipeline\n\n## Citation ##\n\nPlease cite \nH\u00fcbler, R., Key, F.M., Warinner, C. et al. HOPS: automated detection and authentication of pathogen DNA in archaeological remains. Genome Biol 20, 280 (2019) doi:10.1186/s13059-019-1903-0\n\nhttps://www.biorxiv.org/content/10.1101/534198v2\n\n### Example ###\n\n<code bash> java -jar ../path/hops0.3.jar -Xmx600G -input  /path/to/files/*fastq.gz -output /my/output/goes/here -m full </code>\nThis command will execute HOPS with default parameters\nor if you want to do something more specific\n\n<code bash> java -jar ../path/hops0.3.jar -Xmx600G -input  /path/to/files/*fastq.gz -output /my/output/goes/here -m full -c configFile.txt </code>\n\nParameters specified in the config file will overwrite default parameters. All parameters not specified in the config file will stay at their default value. To check what the default values are, check the config file section. **Please note that as the HOPS job will by defaulat call Malt and MaltExtract that HOPS will need enough Heapspace to allow the Malt job to run. Otherwise it will get stuck**\n\n### Example Conda ###\n\n<code bash> hops -Xmx600G -input  /path/to/files/*fastq.gz -output /my/output/goes/here -m full -c configFile.txt </code>\n\n**Please note that as the HOPS job will by defaulat call Malt and MaltExtract that HOPS will need enough Heapspace to allow the Malt job to run. Otherwise it will get stuck**\n\n\n## Test Data ##\n\nTo test if the installation was successfull you can use the resources from the Test_Data folder.\nPease be aware that the database has to be decompressed (table0.db.zip and table0.idx.zip) and the folder Test_Database has to be specified in a config file (see how to do this above) the test reads can be specfied as normal input. You can use the default_list.txt as target list for hops for the test data.\n\n\n## Command Line Parameters ##\n\n**-i --input** Path to input files or directory, depending on which mode you use. For full or malt specify a directory with input fa, fasta , fastq or fq files which can also be gzipped or just list the files. For the maltex mode only rma6 files will be accepted as input for the post mode (still underdevelopment) a folder containing the MaltExtract output has to be used as input\n\n**-m --mode** which mode to use for the pipeline. Accepted values are **full**, which runs malt, malt extract and postprocessing, **malt**, to only execute malt, **maltex** to run malt extract and **post** to run the postprocessing \nYou can use -m me_po to just run MaltExtract and post processing on MALT output \n\n**-c --configFile** specify the path to a valid config file for HOPS which values are mandetory is explained in the config file section of this manual this optional and only necessary to overwrite default values.\n\n**-o --output** specify a valid path to the output directory best avoid all characters reserved for unix prompts\n\n**-h --help** print help\n\n\n### HOPS Input Files ###\n\nTo run MALT or the full mode of HOPS in any case you will need *adapter clipped or adapter clipped and merged*(in case of paired-end) data, as input. Not removing the adapter will result MALT in misalignments. [[add EAGER LINK]]\n\n### Configure your own Screening List for HOPS ###\nTo generate your own screening list you can use the taxas parameter and specify a plain text file\nthat has on each line the name of a species you are interested in. To do that you will have to run HOPS with a Config file.\nYou can check the resource folder for an example. With the conda version you will mostly spared from dealing with it however.\n\n**Example:**\ntaxas=/projects1/clusterhomes/huebler/RMASifte/AMPS/reworkedPathogenListwVirusesFMK_KB_RH_1.txt\nor\ntaxas=/my/folder/myfavortigebugs.txt\n\nyou can just look for one species specifically\n\ntaxas=\"Yersinia pestis\"\n\nor multiple\n\ntaxas=\"Yersinia pestis;Mycobacterium tuberculosis;Bacterium anthracis\"\n\n===== HOPS Output Files =====\n\n==== HOPS MALT Output ====\n\nThe output from MALT are rma6 files found in the ram folder. Those are basically a compressed taxonomic tree, that contains for each Node in the tree, which read is aligned (assigned) to it. You can than inspect the output in MEGAN [[http://megan.informatik.uni-tuebingen.de/]]\n## HOPS MaltExtract Output ##\n\nAccess these files via command line or view it in a text editor. They are located in the ancient and default folders within the amps folder that is generated in the output folder.\n\nFor read distribution and coverage ane reference sequence is chosen to be representive. This will always be the reference with the most alignments.\nThis is necessary as Malt allows reads to have alignments to mutliple references. This however is only a problem for nodes that are not in the leaves of the taxonomic tree.\nthere is a addtional node entries file in the alignment folders to provide some indication on how other files behaved on the same node\n\nIf you use --useTopALignment flag in MaltExtract than all output except read distribution will reflect only all topalignments of these nodes,\nthat option is currently the default in MaltExtract1.4\n=== Coverage ===\n_coverageHist.txt\nTaxon\tReference\t0\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\thigher\nActinomyces_oris\tActinomyces_oris\t1465520\t311419\t310106\t251124\t194992\t138740\t99276\t69300\t54112\t41976\t27670\t78682\n\nthis file is available for each input file and starts by telling the taxonomic node we are analyzing, than the reference that has the most assinged alignments. Lastly we have the number of positions\ncovered 0,1 ,2 .... and so on times while anything covered higher than 10 times is summarized in the higher bin. As HOPS is desinged as a screening tool and not for higher covered data. Spikes in\ncoverage are usually a sign of something going wrong. FOr example reads mappng to conserved regions due to reference bias\n\n_postionsCovered.txt higher than X\n\nTaxon\tReference\tAverageCoverage\tCoverge_StandardDeviation\tpercCoveredHigher1\tpercCoveredHigher2\tpercCoveredHigher3\tpercCoveredHigher4\tpercCoveredHigher5\nActinomyces_oris\tActinomyces_oris\t0.518\t2.027\t0.221\t0.119\t0.068\t0.04\t0.024\n\n\n### Damage Patterns ###\n\n_damageMismatch.txt\nNode\tC>T_1\tC>T_2\tC>T_3\tC>T_4\tC>T_5\tC>T_6\tC>T_7\tC>T_8\tC>T_9\tC>T_10\tG>A_11\tG>A_12\tG>A_13\tG>A_14\tG>A_15\tG>A_16\tG>A_17\tG>A_18\tG>A_19\tG>A_20\tD>V(11Substitution)_1\tD>V(11Substitution)_2\tD>V(11Substitution)_3\tD>V(11Substitution)_4\tD>V(11Substitution)_5\tD>V(11Substitution)_6\tD>V(11Substitution)_7\tD>V(11Substitution)_8\tD>V(11Substitution)_9\tD>V(11Substitution)_10\tH>B(11Substitution)_11\tH>B(11Substitution)_12\tH>B(11Substitution)_13\tH>B(11Substitution)_14\tH>B(11Substitution)_15\tH>B(11Substitution)_16\tH>B(11Substitution)_17\tH>B(11Substitution)_18\tH>B(11Substitution)_19\tH>B(11Substitution)_20\tconsidered_Matches\nActinomyces_oris\t0.38113147410358567\t0.22811386778474826\t0.1265068493150685\t0.10326872039506836\t0.08713955623081063\t0.07130964610861171\t0.05629024440905629\t0.05195253641386238\t0.05465227490094275\t0.04395488932474082\t0.0512072707542051\t0.05394391490537367\t0.05460408904474154\t0.05873861488228218\t0.0754444640028164\t0.08394833948339483\t0.10228668941979523\t0.12681842672413793\t0.22373607274758697\t0.3721667898497167\t0.017623124047259124\t0.013325395370910828\t0.009091226891895756\t0.007938668646919925\t0.008321089167541502\t0.007666419135009274\t0.006591192463455534\t0.007089080675899139\t0.006965138291099348\t0.005887792946301167\t0.005970421202834361\t0.006467250078655744\t0.007429127731631897\t0.006685473422833154\t0.007647351075809306\t0.008448209562207954\t0.007967270735719878\t0.009546741639450544\t0.013146367481755575\t0.017408078712948378\t85817\n\nThe first value is taxonomic unit\nthe next 10 values are C>T substitutions in 5' direction for all alignments for all reads\nthe next 10 values are G>A substitutions in 3' direction for all alignments for all reads\nthe next 10 values are Non C>T substitutions in 5' direction for all alignments for all reads which allows us to estimate noise\nthe next 10 values are Non G>A substitutions in 3' direction for all alignments for all reads which allows us to estimate noise\nthe last node is the number of processed alignments\n\n\n### Mismatch Distribution ###\n\n_editDistance.txt\nTaxon\t0\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\thigher\nActinomyces_oris\t3351\t7926\t11330\t12708\t11302\t10548\t8675\t6875\t4642\t3350\t2076\t3974\n\nFirst column is the target node, returns the editDistance Distribution for all topalingments of reads that are kept after filtering\n\n_percentIdentity.txt\n\nTaxon\t80\t85\t90\t95\t100\nActinomyces_oris\t0\t13569\t36455\t31446\t5287\nFirst Column is the taxonomic Unit and  the next  5\ncolumns gives the number of top alginments of filtered reads that fall into the set percent identitiy bins\n\n#### removed Reads and Alignments ####\n\n_filterTable.txt\nthis file gives some summary statistics for all filtered reads and alignments.\nFirst column is the taxonomic unit\nNode\tNumberOfUnfilteredReads\tNumberOfFilteredReads\tNumberOfUnfilteredAlignments\tnumberOfAlignments\tturnedOn?\nActinomyces_oris\t520523\t520523\t568637\t520523\tOn\n\nthe next two columns are the number of reads prior to filtering and after filtering the difference between those numbers is the number of removed reads\nthe next two columnsare the number of alignments prior and after filtering, the difference between those aolumns is the number if removed alignments\nthe last column gives information on whether destacking was turned on or not (moght be bugged at the moment)\n\n### Read Distribution ###\n\n_additionalNodeEntries.txt\nTargetNode\t01\t02\t03\t04\t05\t06\t07\t08\t09\t10\nActinomyces_oris\tActinomyces_oris;_CP014232.1;_TOPREFPERCREADS100\tActinomyces_naeslundii;_AP017894.1;_TOPREFPERCREADS005\tActinomyces_oris_K20;_AB573870.1;_TOPREFPERCREADS002\tActinomyces_naeslundii;_EU621354.1;_TOPREFPERCREADS001\tActinomyces_naeslundii;_EU621259.1;_TOPREFPERCREADS001\tActinomyces_viscosus;_EU621357.1;_TOPREFPERCREADS001\tActinomyces_viscosus;_EU620893.1;_TOPREFPERCREADS001\tActinomyces_sp._Chiba101;_AP017896.1;_TOPREFPERCREADS001\tActinomyces_viscosus;_EU621241.1;_TOPREFPERCREADS000\tActinomyces_johnsonii;_EU621007.1;_TOPREFPERCREADS000\n\nThis File exits to provide a way for the user to infer how reads distirbute across multiple reference. Reads assigend higher than strain level will have alignments to multiple reference\nthe column are the 10 refernes with the most assinged alignments if the taxonomic unit has less than 10 references sequences the mossing entries will be replaced with a NA\nEach column gives the name of the reference, and the perceantage of alignments assingend to it (when compared to the highest scoring reference)\n\n_alignmentDist.txt\nTaxon\tReference\tuniquePerReference\tnonStacked\tnonDuplicatesonReference\tTotalAlignmentsOnReference\tReferenceLength\nActinomyces_oris\tActinomyces_oris\t0.197\t3298\t26476\t86455\t3042917\nThis file provides information on alignment distribution for the reference sequence that has the most alignments for each taxonomic unit.\nThe first two columns is the the name of the taxon and the name of the referece squence\nthe next is score that gives the fraction of bp that are covered uniquely over all the basepairs of the reads that could theoretically be uniquely mapping.\nSo this score gives some change to estimate overlap. the next three columns is the number of non stacking reads, of non duplicate reads and the total number of alignments assigned to the reference.\nthe last one is the lenght of the reference\n\nTaxon\t25bp\t30bp\t35bp\t40bp\t45bp\t50bp\t55bp\t60bp\t65bp\t70bp\t75bp\t80bp\t85bp\t90bp\t95bp\t100bp\t105bp\t110bp\t115bp\t120bp\t125bp\t130bp\t135bp\t140bp\t145bp\t150bp\t155bp\t160bp\t165bp\t170bp\t175bp\t180bp\t185bp\t190bp\t195bp\t200bp\nActinomyces_oris\t0\t1917\t7111\t10570\t11733\t10835\t8965\t7580\t6250\t4657\t4811\t3022\t2273\t1835\t1117\t962\t716\t655\t548\t407\t277\t245\t177\t94\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\nthe last entry provides for all filtered assinged reads how read length was distributed between 20 and 200 bp \n\n### RunSummary ###\n\nThis file returns for all input files how many reads are assinged to the target taxonomic units after filtering\n\n### TotalCount.txt ###\n\ncontains the total number of assigned reads for all files \n\n## HOPS Postprocessing Output ##\n#### Summary HeatMap ###\nContains a colour-coded heatmap for the HOPS input files. For each input file all pathogens are shown that have passed at least one criterion of post-processing. The pathogens found will be listed on the vertical axis, and the samples will be on the horizontal axis.\n\nThe colour-coding on the heat map is as follows: grey indicates absence, yellow indicates that the DNA fragment(s) match a given reference genome; orange indicates that the DNA fragment(s) match, but there are nucleotide differences, which can possibly be indicative of DNA damage patterns; red indicates that the DNA fragments match and have nucleotide differences that follow a distribution pattern that is more consistent with aDNA damage. An example heat map is provided below. Click to enlarge.\n\n{{ :pathogens:heatmap_overview_wevid.png?200 |}}\n\n### pdf Reports ###\nMore detailed information on every 'hit' so that you can review what post-processing decided and make up your mind if you want to follow up on it. For a description of each of the sections of the pdf report, please see [[https://github.com/keyfm/amps/blob/master/profilePDF_explained.pdf]]\n\n\n## Config File Parameters ##\n\nIn this Section all currently accepted parameters are explained. Please note that it is sufficient to only specify the the parameters you want to overwrite in the the config file. There is a ready to use example config file in /projects1/clusterhomes/huebler/RMASifter/amps/\n\nTo use this online example as a config file, the explanations have to be removed or be located at a new line. While this is a bit cumbersome, ** please, be aware you only need to specify parameters that you want to overwrite. There is really no need specify every parameter that is listed here!!! ** \n\n### Generalparameters ###\n\n**pathToPreProcessing= ../path/to/preprocessing** HOPS has the ability to run a preprocessing script prior to running MALT for example ro get rid off human DNA prior to mapping. The only requirement is that the script has to accept a list of files as input and write output to a aingle folder as fa.gz\n\n**preProcess=0** want to run preprocessing that removes human reads before MALT. 0 = false, 1 = true\n\n## MALT Parameters ##\n\n**index=/projects1/malt/databases/indexed/index040/full-bac-full-vir-etal-nov_2017** path to chosen Malt DB, has to be constructed with MALT version 38 or higher\n\n**id=90.0** set minimum percent identity only matches whose PCI value surpasses this filter will be considered. Please consider that you can set a higher Percent Identity value in MaltExtract. So you can Malt with Percent Identity 85, but run MaltExtract twice with percent identity 85 and 95, for example. Which saves hard disk space.\n\n**m=BlastN** malt mode for this pipeline. the mode should always be BlastN if you plan to use the whole pipeline. But if you for whatever reason need to run BlastX, I made sure you still can do it from the framework of the pipeline.\n\n**at=SemiGlobal** alignmentType! changing the alignment type will probably have *negative effects on the Authenticity criteria calculated* in MaltExtract! This value should only ever be changed by someone who knows what he is doing!\n\n**topMalt=1** Only the highest scoring percentage of alignments will be considered for the LCA algorithm. Increasing this value will result in more alignments being used for the LCA algorithm, which means reads will likely be assigned to nodes higher in the taxonomy.\n\n**sup=1** minimum number of reads to support a node for the LCA algorithm. This means at least one read is necessary to support a node.\n\n**mq=100** maximum number of alignment that can be assinged to a read. Lowering this value will influence the taxonomic assignment and will only be worth it in a few instances.(For example in my hacked Malt version where the LCA can be disabled)\n\n**verboseMalt=1** want verbose output for MALT. 0 = false 1 = true\n\n**memoryMode=load** memoryMode, again only change this value when you are very experienced with the malt source code and or your computation infrastructure somehow requires a different malt mode (which is obviously not the case if you work at this institute)\n\n**additionalMaltParameters=\"\"** add additional parameters separated with \";\". Not all Malt parameters can be explicitly set with AMPS, but those parameters can be specified here! use with caution\n \n## MaltExtract Parameters ##\n\n**filter=def_anc** filter mode uses **def_anc**, **default**, **ancient**, **scan** or **crawl** or **srna** (in development) if in doubt use def_anc, which gives you results for all filtered reads in the default folder and all reads that have at least one damage lesion in their first 5 bases from either end. Default returns statistics for all reads that fullfill all other filter. Ancient requires reads in addition to have one mismatching lesion in their first 5 bases from either end. Scan just returns the number of assigned reads for all nodes without any filtering. runs very fast. Crawl was designed to replace a mapping to a specific reference. Return statistics for all references that match the input species name. For example Yersinia pestis will return statistics for all Yersinia pestis references. This probably the slowest mode. SRNA returns all enrries in terminal nodes it is designed to work with the disable LCA option in cMALT\n\n**taxas=/projects1/users/key/anc5h/soi.backup/List_of_pathogens_KB_fmk12_wViruses1.txt** Species names in following format Yersinia_pesits;Mycobacterium_tuberculosis can be submitted to AMPS directly via the config file or add the path to a taxa file containing the species names separated by new line characters (as you did previously when calling MaltExtract directly)\n\n**resources=/projects1/clusterhomes/huebler/RMASifter/RMA_Extractor_Resources** path to NCBI.map and ncbi.tre files, which can be downloaded from Daniel Husons Megan github page\n\n**topMaltEx=0.01** set top percent value for considered matches. Only the top one percent of matches will be used by default. \n\n**maxLength=0** set a maximum read length. Only reads shorter than this value will be considered (optional). Probably only useful for def_anc or ancient.\n\n**minPIdent=0** set minimum percent identity. Only matches with a value higher than this will be considered. (optional) You can be more strict in MaltExtract than you were in MALT\n\n**verboseMaltEx=0** want verbose output. (0 = false 1 = true, optional ) by default false\n\n**alignment=0** retrieve alignments for all matches that pass the filtering ( 0 = false 1 = true, optional )by default false\n\n**reads=0** retrieve reads that fullfill filtering criteria ( 0 = false 1 = true, optional)\n\n**minComp=0** set minimum complexity between 0.0 and 0.8. Filtering should usually only start when set to 0.6> or higher. While anything higher then 0.7 will be very strict. But maybe test for yourselves\n\n**meganSummary=0** retrieve megan summaries. Which is a file that contains the tree structure and the number of assigned reads for each node but no alignments. This should probably be turned on if clean up is enabled so that you have some idea what the Malt Files originally contained. By default disabled.\n\n**destackingOff=0** turn off destacking. Should only be used in files that are highly covered! (0 = false 1 = true) Otherwise any read that overlaps with any other read will be removed\n\n**dupRemOff=0** turn off removal of duplicate reads (0 = false 1 = true, optional)\n\n**downSampOff=0** turn off downsampling for nodes with more than 10000 assinged reads. Usually we downsample to speed up computation and 10000 assigned reads is sufficient to detect any species in Maltextract!( 0 = false 1 = true, optional)\n\n**useTopAlignment=0** turn on to only use the top alignment for every statistic, except for those concerning read distribution and coverage\n\n## PostProcessing Parameters ##\n\n**pathToList=/projects1/users/key/anc5h/soi.backup/List_of_pathogens_KB_fmk12_wViruses1.txt**  specify path to postprocessing node list\n\n\n## Slurm Parameters ##\n\nIf you use the SLURM schedular you can confige HOPS with a config file to schedule jobs to SLURM directly.\nFor that you will have to change all parameters that refer to the names of partitons and acceptable walltimes. \nYou will have to further turn on SLURM scheduling by adding to the config File\n\n**useSlurm = 1**\n\n### MALT SLURM Parameters ###\n\n**threadsMalt=32** set Threads for MALT when using slrum\n\n**maxMemoryMalt=650** set maximum Memory for MALT in GB!!! to use with slurm\n\n**partitionMalt=long** Set Optional partition for malt optional default will use batch\n\n**wallTimeMalt=48:00:00** A walltime can be set for MALT if the queue is changed from long to medium. Usually this parameter is neither set nor used. Use this only if you are sure your job can finish in 48 hours!\n\n\n### MaltExtract Slurm Parameters ###\n\n**threadsMaltEx=20** set number of Threads for MaltExtract. Should never be higher than the number of input files!\n\n**maxMemoryMaltEx=300** set maximum Memory in GB!!!! for MALTExtract. \n\n**partitionMaltEx=medium** optional set partition for MaltExtract. You can change to long in very big jobs. But I am not sure if it is advisable to change to short\n\n**wallTimeME =48:00:00** While it is possible to decrease the Walltime for MaltExtract this should only be done in very small jobs\n\n### PostProcessing Slurm Parameters ###\n\n**threadsPost=2** set number of threads to use in postprocessing\n\n**partitionPost=short** set partition for postprocessing\n\n**maxMemoryPost=10** set Max Memory for Postprocessing\n\n**wallTimePost=1:00:00** set walltime for postprocessing\n\n### PreProcessing Slurm Parameters ###\n\n**wallTimePreProcessing= 48:00:00** Set walltime for preprocessing will only be used if partition is changed to medium or short but this only a viable option in small jobs\n\n**partitionPreProcessing=long** by default preproceeing will queue in long queue but you can change this\n\n**threadsPreProcessing=32** number of treads used for preprocessing, by default 32 threads will be used. As the shellscript itself will only require 32 cores, this parameter should only be changed when you also change the preprocessing script itself\n\n**memoryPreProcessing=500** change the number reserved memory for preprocessing\n\n"
}