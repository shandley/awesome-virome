{
  "cache_date": "2025-11-01T10:33:11.755327",
  "data": "# VGEA [![DOI](https://zenodo.org/badge/236802599.svg)](https://zenodo.org/badge/latestdoi/236802599)\n\nVGEA (Viral Genomes Easily Analyzed) is an RNA viral assembly toolkit.\n\nVGEA was developed to aid in the analysis of next generation sequencing data. Users can do the following with this pipeline:\n\n* Remove adapters, low quality bases/positions, and perform read-level QC \n* Align paired-end sequencing reads to the human reference genome.\n* Extract unmapped/unaligned reads.\n* Split bam files into forward and reverse reads. \n* Carry out de novo assembly of forward and reverse reads to generate contigs.\n* Pre-process reads for quality and contamination. \n* Map reads to a reference tailored to the sample using corrected contigs supplemented by the user\u2019s choice of reference sequences.\n* Evaluate/assess the quality of genome assemblies.\n* Collate results in a multiqc summary..\n\nDependencies: \n\nThe VGEA pipeline requires the following dependencies:\n\n* Snakemake (K\u00f6ster et al., 2012)\n* Fastp (Chen et al., 2018)\n* BWA (Li and Durbin, 2009)\n* Samtools (Li et al., 2009)\n* IVA (Hunt et al., 2015)\n* Shiver (Wymant et al., 2018)\n* SeqKit (Shen et al., 2016)\n* Quast (Gurevich et al., 2013)\n* Multiqc (Ewels et al., 2016)\n\nVGEA was built on the Snakemake workflow management system and utilizes existing tools for each step: **fastp** (Chen et al., 2018) for read trimming and quality control, **bwa** (Li and Durbin, 2009) for mapping sequencing reads to the human reference genome, **samtools** (Li et al., 2009) for extracting unmapped reads and also for splitting bam files into fastq files, **iva** (Hunt et al., 2015) for de novo assembly to generate contigs, **shiver** (Wymant et al., 2018) to pre-process reads for quality and contamination, then map to a reference tailored to the sample using corrected contigs supplemented with the user\u2019s choice of existing reference sequences, **seqkit** for cleaning shiver assembly for QUAST and **quast** (Gurevich et al., 2013) to evaluate/assess the quality of genome assemblies. \nFinally, an interactive report of results are generated by **MultiQC** (Ewels et al., 2016).\n\n## Installation \n\n### 1. Conda\n\nThis workflow requires conda to be installed and available on the system.\n\nTo do this install conda via the miniconda installers found [here](https://docs.conda.io/en/latest/miniconda.html) and instructions [here](https://docs.conda.io/projects/continuumio-conda/en/latest/user-guide/install/index.html).\n\nBriefly: \n\n#### Linux\n\n  To obtain the installer for linux use the following:\n```\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n```\n\n  Then, install miniconda,\n\n```\nsh Miniconda3-latest-Linux-x86_64.sh\n```\n\n#### MacOS\n\n  To obtain the installer for MacOS, you can [download](https://docs.conda.io/en/latest/miniconda.html) it manually or use wget:\n```\nwget https://repo.continuum.io/miniconda/Miniconda3-latest-MacOSX-x86_64.sh\n```\n\n  Then, install miniconda,\n\n```\nsh Miniconda3-latest-MacOSX-x86_64.sh\n```\n### 2. Snakemake\n\nThen install snakemake as follows:\n\n    conda create -c bioconda -c conda-forge --name snakemake snakemake \n\n### 3. VGEA \n\nTo complete installation of VGEA clone the directory and enter it.\n\n```\ngit clone git@github.com:pauloluniyi/VGEA.git\ncd VGEA\n```\n\n### 4. Data Dependency\n\nFinally, you need to download a human reference genome. \nThere is a convenience script provided to do this that can run as follows:\n\n```\ncd resources/\nbash get_human_reference.sh \ncd ..\n```\n\n## Usage\n\nThere are 2 key files when running VGEA:\n\n- A yaml config file containing key parameters e.g., `config/config.yaml`\n \n- A 3 column tab-seperated sheet with a name and paths to r1 and r2 for each sample e.g., `./tests/integration/sample_table.tsv`\n\n### Config\n\n- `sample_table` is the path to the tsv created above with names and read locations for each sample (under headings id, r1, r2)\n\n- `shiver_config_file` is the path to the config file for shiver, by default this is `config/shiver_config.sh`\n\n- `human_reference_genome` is the path to the fasta file containing the human genome reference, if you used `get_human_reference.sh` this will be `resources/GRCh38_latest_genomic.fna`\n\n- `viral_species` is one of the 4 pre-supported viral references (`HIV-1`, `SARS-CoV-2`, `LASV_L`, `LASV_S`) and is used to autofill the paths to various reference files used by default for these. If you supply your own viral reference/adapter/primer files then this doesn't need to be supplied\n\n- `viral_reference_alignment` path to a reference alignment of the appropriate viral genomes for your samples (by default `resources/{viral_species}/MyRefAlignment.fasta`). This reference alignment should be carefully created. \n\"An alignment of existing reference sequences is required as input for shiver. Construction of a custom reference for mapping involves identifying the existing references that are closest to the sample under consideration. The greater the number and diversity of existing references given as input, the denser and broader the coverage of sequence space is, and the closer the closest reference is expected to be, with corresponding benefits for the accuracy of the results. However these existing references should be aligned to each other accurately, in order for the addition of each sample\u2019s contigs to the alignment to be meaningful; this means that producing such an input by automatically aligning a large number of diverse sequences without checking the results would be a bad idea. This alignment will be used as input for every sample in a dataset processed by shiver, and so the user is advised to put a little thought into sequence selection and manually curating the alignment if needed.\" (Wymant et al., 2018).  \n\n- `viral_reference_genome` path to a singular reference genome for your samples for QUAST based assembly assessment (by default `resources/{viral_species}/MyRefGenome.fasta`).\n\n- `viral_reference_gene_features` path to a GFF3 containing gene features for the supplied viral reference genome (by default `resources/{viral_species}/MyRefFeatures.gff3`)\n\n- `viral_sequencing_adapters` path to a fasta file containing the sequencing adapters used for your samples (by default `resources/{viral_species}/MyAdapters.fasta`)\n\n- `viral_sequencing_primers` path to a fasta file containing the sequencing primers used for your samples (by default `resources/{viral_species}/MyRefAlignment.fasta`)\n\n### Sample Table\n\nA 3 column, tab-separated file with an *id* column containing sample names, *r1* with the path to the forward reads for that sample, and *r2* with the path to reverse reads for that sample.\n\n\n    id\tr1\tr2\n    test1\t.tests/integration/test1_r1.fq.gz\t.tests/integration/test1_r2.fq.gz\n    test2\t.tests/integration/test2_r1.fq.gz\t.tests/integration/test2_r2.fq.gz\n\n### Executing the workflow\n\nThe workflow will automatically install dependencies using conda/mamba if executed with `--use-conda` otherwise all dependencies listed at the start of the README must be manually installed via conda.\n\nTo run the workflow complete the above config and sample tables and execute:\n\n```\nsnakemake --cores $n --use-conda --configfile $your_config\n```\n\nWhere `$n` is the number of cores with which to execute the workflow and `$your_config` is the path to `config.yaml` you've created.\n\n### Results\n\nVGEA will output all results in the `results/` directory with a subfolder containing results for each sample and top-level folders collecting all log files, tool benchmarks, and an interactive multiQC html summary of results.\n\n    results/\n    \u251c\u2500\u2500 benchmarks                  # all benchmark files with hardware usage for each sample\n    \u251c\u2500\u2500 logs                        # all log files for each rule and sample\n    \u251c\u2500\u2500 multiqc                     # multiqc summary of quast, fastp, and de-hosting results\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 multiqc_data\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 multiqc_report.html     # the interactive multiqc report\n    \u251c\u2500\u2500 test1                       # all results for the sample \"test1\" \n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 shiver                  # folder containing all shiver output files \n    \u2502   \u251c\u2500\u2500 test1_1.fastq           # fastp trimmed and de-hosted reads for the sample \n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 test1_2.fastq\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 test1.bam               # alignment against human reference \n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 test1.fasta             # final cleaned assembly from IVA and shiver\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 test1.fastp.html        # fastp report in html format\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 test1.fastp.json        # fastp report in json format\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 test1.flagstat          # dehosting mapping statistics\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 test1_iva               # folder containing all IVA assembly files\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 test1.quast_results     # folder containing all QUAST assembly assessment of test1.fasta\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 test1_r1_trimmed.fq     # fastp trimmed reads\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 test1_r2_trimmed.fq     \n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 test1.sam               # sam file containing all the reads that didn't map to the human reference\n    \u2514\u2500\u2500 test2\n        \u251c\u2500\u2500 shiver\n        \u251c\u2500\u2500 test2_1.fastq\n        \u251c\u2500\u2500 test2_2.fastq\n        \u251c\u2500\u2500 test2.bam\n        \u251c\u2500\u2500 test2.fasta\n        \u251c\u2500\u2500 test2.fastp.html\n        \u251c\u2500\u2500 test2.fastp.json\n        \u251c\u2500\u2500 test2.flagstat\n        \u251c\u2500\u2500 test2_iva\n        \u251c\u2500\u2500 test2.quast_results\n        \u251c\u2500\u2500 test2_r1_trimmed.fq\n        \u251c\u2500\u2500 test2_r2_trimmed.fq\n        \u2514\u2500\u2500 test2.sam\n\n## Containerized Singularity (Beta)\n\nAlternatively, users can run the VGEA pipeline with all dependencies installed in a docker/singularity container.\n\nThis requires singularity and snakemake to be installed on the system but in theory provides a more reproducible version of the conda environments (not fully tested compared to just conda).\n\nSee [here](https://www.sylabs.io/docs/) for instructions to install Singularity.\n\nThen the workflow can be run as normal with `--use-singularity` added e.g.,\n\n```\nsnakemake --use-conda --use-singularity --configfile .tests/integration/test_config.yaml -j 1\n```\n\n## Testing\n\nTo run a minimal integration test once snakemake and conda are installed:\n\n```\nsnakemake --use-conda --configfile .tests/integration/test_config.yaml -j 1\n```\n\n# Contributions\n\n- Paul Eniola Oluniyi\n- Gerry Tonkin-Hill (https://gtonkinhill.github.io/)\n- Finlay Maguire (https://finlaymagui.re)\n\n\n[![DOI](https://zenodo.org/badge/236802599.svg)](https://zenodo.org/badge/latestdoi/236802599)\n"
}