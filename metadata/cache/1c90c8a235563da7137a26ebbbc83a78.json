{
  "cache_date": "2025-03-17T02:18:05.231614",
  "data": "# VirHunter\n![VirHunter logo](media/logo.png?raw=true \"VirHunter logo\")\n\n**VirHunter** is a tool that uses deep learning to identify viruses in plant virome sequencing datasets. In particular, VirHunter classifies previously assembled contigs into virus, host and bacteria classes.\n\n## Useful Info\n* Recently we uploaded VirHunter to [Galaxy Europe](https://usegalaxy.eu/root?tool_id=toolshed.g2.bx.psu.edu/repos/iuc/virhunter/virhunter/1.0.0+galaxy1). This means that now you can run VirHunter on your data without installation!\n* If you want to get rid of phage or fungi contamination please check out [Decontaminator](https://github.com/cbib/decontaminator). \nIt goes well along with VirHunter!\n* Finally, [here](https://www.frontiersin.org/articles/10.3389/fbinf.2022.867111/full) is the original publication on VirHunter. Please cite it, when you use VirHunter.\nIf you are looking for a more practical explanation of VirHunter check out this [presentation](media/virhunter_description.pdf).\n\n## System Requirements\nVirHunter installation requires a Unix environment with [python 3.8](http://www.python.org/). \nIt was tested on Linux and macOS operating systems. \nFor now, VirHunter is still not fully compatible with M1 chip MacBook.\n\nIn order to run VirHunter you need to have git and conda already installed. \nIf you are installing conda for the first time, we suggest you to use \na lightweight [miniconda](https://docs.conda.io/en/latest/miniconda.html).\nOtherwise, you can use pip for the dependencies' installation.\n         \n## Installation \n\nTo install VirHunter, you need to download it from github and then to install the dependencies.\n\nFirst, clone the repository from [github](https://github.com/cbib/virhunter)\n\n```shell\ngit clone https://github.com/cbib/virhunter.git\n```\n\nGo to the VirHunter root folder\n\n```shell\ncd virhunter/\n```\n\n\n### Installing dependencies with Conda\n\nFirst, you have to create the environment from the `envs/environment.yml` file. \nThe installation may take around 500 Mb of drive space. \n\n```shell\nconda env create -f envs/environment.yml\n```\n\nSecond, activate the environment:\n\n```shell\nconda activate virhunter\n```\n\n### Installing dependencies with pip\n\nIf you don't have Conda installed in your system, you can install python dependencies via pip program:\n\n```shell\npip install -r envs/requirements.txt\n```\n\nThen if you have macOS you will need to install `wget` library to run some scripts (Conda installation already has it). You can do this with `brew` package manager.\n\n```shell\nbrew install wget\n```\n\n### Testing your installation of VirHunter\n\nYou can test that VirHunter was successfully installed on the toy dataset we provide. \nIMPORTANT: the toy dataset is intended only to test that VirHunter has been well installed and all the scripts can be executed. \nThese modules should not be used for prediction on your owd datasets!\n\nFirst, you have to download the toy dataset\n```shell\nbash scripts/download_test_installation.sh\n```\nThen run the bash script that calls the testing, training and prediction python scripts of VirHunter.\nAttention, the training process may take some time (up to an hour).\n```shell\nbash scripts/test_installation.sh\n```\n\n## Using VirHunter for prediction\n\nTo run VirHunter you can use the already pre-trained models or train VirHunter yourself (described in the next section).\nPre-trained model weights are already available for the multiple host plants. \nYou can download them using the `download_weights.sh` script.\n\n```shell\nbash scripts/download_weights.sh \n```\n\nBefore launching the prediction you will need to fill the `configs/predict_config.yaml` file. \nIf for example, you want to use the weights of the pretrained model for peach, \nyou should change the field `weights` in the `configs/predict_config.yaml` to `weights/peach`.\n\nVirHunter supports prediction for multiple test files at once. \nFor that you need to change a bit the field `test_ds` in the\n`configs/predict_config.yaml`. \n\n```yaml\npredict:\n    test_ds:\n      - /path/to/test_ds_1\n      - /path/to/test_ds_2\n      - /path/to/test_ds_3  \n```\n\nOnce the config file is ready, you can start the prediction:\n\n```shell\npython virhunter/predict.py configs/predict_config.yaml\n```\n\nAfter prediction VirHunter produces two `csv` files and one optional `fasta` file:\n\n1. The first file ends with `_predicted_fragments.csv`\nIt is an intermediate result containing predictions of the three CNN networks (probabilities of belonging to each of the virus/plant/bacteria class) and of the RF classifier for each fragment of every contig.\n\n2. The second file ends with `_predicted.csv`. \nThis file contains final predictions for contigs calculated from the previous file. \n   - `id` - fasta header of a contig.\n   - `length` - length of the contig.\n   - `# viral fragments`, `# plant fragments` and `# bacterial fragments` - the number of fragments of the contig that received corresponding class prediction by the RF classifier.\n   - `decision` - class given by the VirHunter to the contig.\n   - `# viral / # total` - number of viral fragments divided by the total number of fragments of the contig.\n\n3. The optional fasta file ends with `_viral.fasta`. It contains contigs that were predicted as viral by VirHunter.\nTo generate it you need to set flag `return_viral` to `True` in the config file.\n\n`configs/predict_config.yaml` has a field `limit` that is used to discard contigs that are shorter than `limit` from prediction. \nWe tested limit of 750 in the paper and suggest using it as a default one. You can change the limit, but we do not guarantee VirHunter performance then.\n\n\n## Available models\nWe have trained 8 models of VirHunter:  _carrot_, _grapevine_, _lettuce_, _peach_, _rice_, _sugar beet_, _tomato_ and _generalistic_.\nThe last model was prepared with a mixture of plants from _dicots_ and _monocots_ clades. \n\nWe recommend to use individual plant models, when the host plant of the virome belongs to the same family. \nIn other cases you can use _generalistic_ model. \n\n\n## Training your own model\n\nYou can train your own model, for example for a specific host species. Before training, you need to collect sequence \ndata for training for three reference datasets: _viruses_, _bacteria_ and _host_. \nExamples are provided by running `scripts/download_test_installation.sh` that will download `viruses.fasta`, \n`host.fasta` and `bacteria.fasta` files (real reference datasets should correspond \ne.g. to the whole genome of the host, all bacteria and all viruses from the NCBI).\n\nTraining requires execution of the following steps:\n- prepare the training dataset for the neural network and Random Forest modules from fasta files with `prepare_ds.py`.\n- train the neural network and Random Forest modules with `train.py`\n\nThe training will be done twice - for fragment sizes of 500 and 1000.\n\nThe successful training of VirHunter produces weights for the three neural networks from the first module and weights for the \ntrained Random Forest classifier for fragment sizes of 500 and 1000. They can be subsequently used for prediction.\n\nTo execute the steps of the training you must first create a copy of the `template_config.yaml`. \nThen fill in the necessary parts of the config file. No need to fill in all tasks! \nOnce config file is filled you can launch the scripts consecutively providing them with the config file like this:\n```shell\npython virhunter/prepare_ds.py configs/config.yaml\n```\nAnd then\n```shell\npython virhunter/train.py configs/config.yaml\n```\nImportant to note, the suggested number of epochs for the training of neural networks is 10.\n\n### Complex dataset preparation\nIf you want to prepare dataset that would have host oversampling for chloroplast and CDS (like it was done in the paper), \nyou can use `prepare_ds_complex.py` script. Compared to `prepare_ds.py` it will require paths to CDS and chlroplast containing fasta files.\n\n### Training VirHunter on GPU\n\nIf you plan to train VirHunter on GPU, please use `environment_gpu.yml` or `requirements_gpu.txt` for dependencies installation.\nThose recipes were tested only on the Linux cluster with multiple GPUs.\nIf you plan to train VirHunter on cluster with multiple GPUs, you will need to uncomment line with\n`CUDA_VISIBLE_DEVICES` variable and replace `\"\"` with `\"N\"` in header of `train_nn.py`, where N is the number of GPU you want to use.\n\n```python\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"N\"\n```\n\n## VirHunter for galaxy\n`virhunter_galaxy` folder contains modified scripts for the galaxy version of virhunter.\n"
}